import 'dart:io';
import 'ai_service.dart';
import 'database_service.dart';
import 'embedding_service.dart';
import '../models/journal_file.dart';
import '../models/conversation_session.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'dart:async';
import 'dart:math' as math;
import '../models/context_settings.dart';

class JournalCompanionService {
  static final JournalCompanionService _instance = JournalCompanionService._internal();
  factory JournalCompanionService() => _instance;
  JournalCompanionService._internal();

  final AIService _aiService = AIService();
  final DatabaseService _dbService = DatabaseService();
  final EmbeddingService _embeddingService = EmbeddingService();

  /// Generate AI insights based on user query using embeddings-based context
  Future<String> generateInsights({
    required String userQuery,
    ConversationSession? conversation,
    required ContextSettings settings,
  }) async {
    
    
    // Try multiple log approaches to see if any work
    stderr.writeln('STDERR: generateInsights called with query: $userQuery');
    
    // Force flush stdout
    stdout.writeln('STDOUT: generateInsights method entry');
    

          try {
      
      // Get user token setting
      final userTokens = await _getUserTokenSetting();
      
      
      // 1. CORE CONTEXT (Always included, minimal tokens)
      final conversationContext = _getConversationHistory(conversation, 300);
      
      // 2. PINNED CONTEXT (User-selected important content)
      final pinnedContext = await _getPinnedContent(userTokens ~/ 3); // Use up to 1/3 of tokens for pinned content
      final pinnedTokensUsed = _estimateTokens(pinnedContext);
      
      // 3. CUSTOM CONTEXT (Use what's actually needed, not a fixed budget)
      final customContext = await _getCustomContext(settings, userTokens); 
      final customTokensUsed = _estimateTokens(customContext);
      
      // 4. EMBEDDINGS (Gets remaining tokens)
      final coreTokensUsed = 300 + pinnedTokensUsed; // conversation(300) + pinned(actual usage)
      final remainingTokensForEmbeddings = userTokens - coreTokensUsed - customTokensUsed;
      
      final relevantEntries = await _getRelevantEntriesFromEmbeddings(userQuery, remainingTokensForEmbeddings);
      
      return await _generateCleanResponse(
        userQuery: userQuery,
        relevantEntries: relevantEntries,
        conversationContext: conversationContext,
        customContext: customContext,
        pinnedContext: pinnedContext,
      );
      
    } catch (e) {
      
      return 'Sorry, I had trouble processing your question. Please try again.';
    }
  }

  /// Get user's saved token setting from SharedPreferences
  Future<int> _getUserTokenSetting() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final tokens = prefs.getDouble('context_token_usage') ?? 30000.0;
      return tokens.toInt();
    } catch (e) {
      print('   Using default tokens (SharedPreferences error): $e');
      return 30000; // Fallback to default
    }
  }



  /// Get conversation history (last 10 exchanges)
  String _getConversationHistory(ConversationSession? conversation, int tokenBudget) {
    try {
      if (conversation?.history.isEmpty != false) {
        print('   ‚ö†Ô∏è No conversation history');
        return '';
      }
      
      print('   üí¨ Building conversation context...');
      
      // Get recent messages (last 3 exchanges = 6 messages max) - reduced to avoid confusion
      final recentHistory = conversation!.history.reversed.take(6).toList().reversed.toList();
      
      final conversationLines = <String>[];
      int usedTokens = 0;
      
      for (final message in recentHistory) {
        final line = '${message.role == 'user' ? 'User' : 'Assistant'}: ${message.content}';
        final lineTokens = _estimateTokens(line);
        
        if (usedTokens + lineTokens <= tokenBudget) {
          conversationLines.insert(0, line);
          usedTokens += lineTokens;
        } else {
          break;
        }
      }
      
      print('   ‚úÖ Conversation truncated: ${usedTokens} tokens');
      return conversationLines.join('\n');
      
    } catch (e) {
      print('Error building conversation context: $e');
      return 'No conversation context available.';
    }
  }

  /// Get relevant entries using embeddings search
  Future<String> _getRelevantEntriesFromEmbeddings(String userQuery, int tokenBudget) async {
    try {
      print('   üîç Searching embeddings for relevant entries...');
      print('   Query: "$userQuery"');
      print('   Token budget: $tokenBudget');
      
      // First, check if any embeddings exist in the database
      final embeddingCount = await _dbService.getEmbeddingCount();
      print('   üìä Total embeddings in database: $embeddingCount');
      
      if (embeddingCount == 0) {
        print('   ‚ö†Ô∏è No embeddings found in database - files need to be imported first');
        return 'No relevant entries found. Import some journal files to enable AI search.';
      }
      
      // Show sample of what embeddings exist
      final sampleEmbeddings = await _dbService.getEmbeddingSample(limit: 3);
      print('   üìã Sample embeddings:');
      for (final sample in sampleEmbeddings) {
        print('     - ${sample['name']}: chunk ${sample['chunk_index']}, ${sample['content_length']} chars, ${sample['embedding_size']} bytes');
      }
      
      // Find most similar files using embeddings
      print('   üéØ About to call findSimilarFiles with query: "$userQuery"');
      final similarFiles = await _embeddingService.findSimilarFiles(userQuery, topK: 10);
      print('   üéØ Found ${similarFiles.length} similar files from chunked embeddings');
      
      if (similarFiles.isEmpty) {
        print('   ‚ö†Ô∏è CRITICAL: Embedding search returned NO RESULTS');
        print('   üîç This suggests an issue with the similarity calculation or thresholds');
        return 'No relevant entries found for your query.';
      }
      
      final relevantEntries = <String>[];
      int currentTokens = 0;
      int skippedDueToTokens = 0;
      int skippedDueToEmptyContent = 0;
      
      print('   üìÑ Processing ${similarFiles.length} files:');
      for (int i = 0; i < similarFiles.length && currentTokens < tokenBudget; i++) {
        final file = similarFiles[i];
        print('   üìÑ Processing file ${i + 1}/${similarFiles.length}: ${file.name}');
        print('       Content length: ${file.content.length} chars');
        
        // Get clean content
        final cleanContent = _extractUserContentOnly(file.content);
        final entryTokens = _estimateTokens(cleanContent);
        
        print('     üìä Clean content: ${cleanContent.length} chars, ~$entryTokens tokens');
        print('     üìä Current tokens: $currentTokens, Budget: $tokenBudget, Would use: ${currentTokens + entryTokens}');
        
        if (cleanContent.isEmpty) {
          print('     ‚ùå SKIPPED: Empty content after filtering');
          skippedDueToEmptyContent++;
          continue;
        }
        
        if (currentTokens + entryTokens > tokenBudget) {
          print('     ‚ùå SKIPPED: Would exceed token budget ($tokenBudget)');
          skippedDueToTokens++;
          break;
        }
        
        final entry = '**${file.name}** (${file.journalDate?.toString().split(' ')[0] ?? 'No date'}):\n$cleanContent';
        relevantEntries.add(entry);
        currentTokens += entryTokens;
        print('     ‚úÖ Added to context (total tokens: $currentTokens)');
      }
      
      print('   üìä FINAL STATS:');
      print('     - Files processed: ${similarFiles.length}');
      print('     - Files added to context: ${relevantEntries.length}');
      print('     - Skipped due to empty content: $skippedDueToEmptyContent');
      print('     - Skipped due to token budget: $skippedDueToTokens');
      print('     - Total tokens used: $currentTokens');
      
      if (relevantEntries.isEmpty) {
        print('   ‚ö†Ô∏è CRITICAL: No entries had usable content after filtering');
        if (skippedDueToEmptyContent > 0) {
          print('   üîç Problem: All $skippedDueToEmptyContent files had empty content after filtering');
        }
        if (skippedDueToTokens > 0) {
          print('   üîç Problem: $skippedDueToTokens files skipped due to token budget');
        }
        return 'No relevant entries found for your query.';
      }
      
      final result = relevantEntries.join('\n\n');
      print('   üéØ SUCCESS: Returning ${relevantEntries.length} relevant entries (~$currentTokens tokens)');
      return result;
      
    } catch (e) {
      print('   üî¥ Error in embedding search: $e');
      print('   üî¥ Stack trace: ${StackTrace.current}');
      return 'Error searching for relevant entries: $e';
    }
  }

  /// Get custom context for selected files (NEEDS-BASED SYSTEM)
  Future<String> _getCustomContext(ContextSettings settings, int maxTokenBudget) async {
    try {
      if (settings.selectedFileIds.isEmpty) {
        return '';
      }
      
      print('   üìÅ Loading ${settings.selectedFileIds.length} selected files (needs-based system)...');
      
      final selectedFiles = <String>[];
      int totalTokensNeeded = 0;
      final maxReasonableLimit = (maxTokenBudget * 0.6).toInt(); // Don't let custom files dominate
      
      for (final fileId in settings.selectedFileIds) {
        
        try {
          final file = await _dbService.getFile(fileId);
          if (file?.content?.isNotEmpty == true) {
            // Clean the content
            final cleanContent = _extractUserContentOnly(file!.content!);
            if (cleanContent.trim().isEmpty) {
              print('   ‚è≠Ô∏è Skipping ${file.name} - no user content after cleaning');
              continue;
            }
            
            final fileTokens = _estimateTokens(cleanContent);
            
            // Check if adding this file would exceed reasonable limits
            if (totalTokensNeeded + fileTokens > maxReasonableLimit) {
              print('   ‚èπÔ∏è Stopping at ${file.name} - would exceed reasonable limit (${maxReasonableLimit} tokens)');
              break;
            }
            
            selectedFiles.add('${file.name}:\n$cleanContent');
            totalTokensNeeded += fileTokens;
            print('   ‚úÖ Added ${file.name} (${fileTokens} tokens)');
            
          } else {
            print('   ‚è≠Ô∏è Skipping ${file?.name ?? 'unknown'} - no content');
          }
        } catch (e) {
          print('   ‚ùå Error loading file $fileId: $e');
        }
      }
      
      if (selectedFiles.isNotEmpty) {
        final result = selectedFiles.join('\n\n');
        print('   ‚úÖ Custom context: ${selectedFiles.length} files, ${totalTokensNeeded} tokens used');
        return result;
      }
      
      return '';
      
    } catch (e) {
      print('Error getting custom context: $e');
      return '';
    }
  }

  /// Get pinned content for AI context (includes both files and folders)
  Future<String> _getPinnedContent(int tokenBudget) async {
    try {
      print('   üìå Loading pinned content...');
      
      // Get both pinned files and folders
      final pinnedFiles = await _dbService.getPinnedFiles();
      final pinnedFolders = await _dbService.getPinnedFolders();
      
      if (pinnedFiles.isEmpty && pinnedFolders.isEmpty) {
        print('   ‚ö†Ô∏è No pinned files or folders found');
        return '';
      }
      
      print('   üìå Found ${pinnedFiles.length} pinned files and ${pinnedFolders.length} pinned folders');
      
      final pinnedEntries = <String>[];
      int usedTokens = 0;
      
      // Process pinned files first
      for (final file in pinnedFiles) {
        if (file.content.isNotEmpty) {
          // Clean the content
          final cleanContent = _extractUserContentOnly(file.content);
          if (cleanContent.trim().isEmpty) continue;
          
          final entry = '${file.name}:\n$cleanContent';
          final entryTokens = _estimateTokens(entry);
          
          if (usedTokens + entryTokens <= tokenBudget) {
            pinnedEntries.add(entry);
            usedTokens += entryTokens;
            print('   ‚úÖ Added pinned file: ${file.name} (${entryTokens} tokens)');
          } else {
            print('   ‚èπÔ∏è Pinned content budget reached, stopping at file ${file.name}');
            break;
          }
        }
      }
      
      // Process pinned folders (get all files within them)
      for (final folder in pinnedFolders) {
        if (usedTokens >= tokenBudget) {
          print('   ‚èπÔ∏è Pinned content budget reached, skipping folder ${folder.name}');
          break;
        }
        
        try {
          final folderFiles = await _dbService.getFiles(folderId: folder.id);
          print('   üìÅ Processing pinned folder "${folder.name}" with ${folderFiles.length} files');
          
          for (final file in folderFiles) {
            final fileContent = await _dbService.getFile(file.id);
            if (fileContent?.content?.isNotEmpty == true) {
              final cleanContent = _extractUserContentOnly(fileContent!.content!);
              if (cleanContent.trim().isEmpty) continue;
              
              final entry = '${folder.name}/${file.name}:\n$cleanContent';
              final entryTokens = _estimateTokens(entry);
              
              if (usedTokens + entryTokens <= tokenBudget) {
                pinnedEntries.add(entry);
                usedTokens += entryTokens;
                print('   ‚úÖ Added file from pinned folder: ${folder.name}/${file.name} (${entryTokens} tokens)');
              } else {
                print('   ‚èπÔ∏è Pinned content budget reached, stopping at folder file ${folder.name}/${file.name}');
                break;
              }
            }
          }
        } catch (e) {
          print('   ‚ùå Error processing pinned folder ${folder.name}: $e');
        }
      }
      
      if (pinnedEntries.isNotEmpty) {
        final result = pinnedEntries.join('\n\n');
        print('   ‚úÖ Pinned context: ${pinnedEntries.length} entries (${pinnedFiles.length} files + ${pinnedFolders.length} folders), ${usedTokens} tokens');
        return result;
      }
      
      return '';
      
    } catch (e) {
      print('Error loading pinned content: $e');
      return '';
    }
  }

  /// Generate a clean response using the AI service
  Future<String> _generateCleanResponse({
    required String userQuery,
    required String relevantEntries,
    required String conversationContext,
    required String customContext,
    required String pinnedContext,
  }) async {
      
    final systemPrompt = '''You are a close friend who knows this person well. Respond naturally and directly, like you would in any normal conversation. Be warm, authentic, and helpful.''';

    // Build a conversational prompt that weaves context naturally
    final prompt = _buildConversationalPrompt(
      userQuery: userQuery,
      conversationContext: conversationContext,
      pinnedContext: pinnedContext,
      relevantEntries: relevantEntries,
      customContext: customContext,
    );

    return await _generateCompleteResponse(prompt, systemPrompt);
  }

  /// Build a natural, conversational prompt that integrates context smoothly
  String _buildConversationalPrompt({
    required String userQuery,
    required String conversationContext,
    required String pinnedContext,
    required String relevantEntries,
    required String customContext,
  }) {
    final parts = <String>[];
    
    // Start with the user's actual question/statement
    parts.add(userQuery);
    
    // Add conversational context if we have recent chat history
    if (conversationContext.isNotEmpty) {
      parts.add('\n--- Our Recent Conversation ---');
      parts.add(conversationContext);
    }
    
    // Integrate relevant background information naturally
    final backgroundInfo = <String>[];
    
    if (pinnedContext.isNotEmpty) {
      backgroundInfo.add('Important context you should know:\n$pinnedContext');
    }
    
    if (customContext.isNotEmpty) {
      backgroundInfo.add('Specific entries you wanted me to consider:\n$customContext');
    }
    
    if (relevantEntries.isNotEmpty) {
      backgroundInfo.add('Related things you\'ve written about:\n$relevantEntries');
    }
    
    // Add background info conversationally
    if (backgroundInfo.isNotEmpty) {
      parts.add('\n--- Background Context ---');
      parts.addAll(backgroundInfo);
      parts.add('\n--- End Context ---');
      parts.add('\nNow, knowing all of this about you and what you\'ve shared, here\'s what I think about your question...');
    }
    
    return parts.join('\n');
  }

  /// Generate a complete response with natural completion
  Future<String> _generateCompleteResponse(String prompt, String systemPrompt) async {
    // Let AI complete naturally with character limit
    final response = await _aiService.generateTextNaturally(
      prompt,
      temperature: 0.5, // LOWER - More focused and direct responses
      systemPrompt: systemPrompt,
    );
    
    // Apply character limit with smart truncation
    return _applyResponseLimit(response.trim());
  }

  /// Apply response character limit with smart sentence boundary truncation
  String _applyResponseLimit(String response, {int maxCharacters = 1800}) {
    if (response.length <= maxCharacters) {
      return response;
    }
    
    // Find the last complete sentence within the limit
    final truncated = response.substring(0, maxCharacters);
    
    // Look for sentence endings (., !, ?) working backwards
    final sentenceEndings = ['.', '!', '?'];
    int lastSentenceEnd = -1;
    
    for (int i = truncated.length - 1; i >= maxCharacters - 200; i--) {
      if (sentenceEndings.contains(truncated[i])) {
        // Make sure it's not an abbreviation by checking if next char is space or end
        if (i == truncated.length - 1 || truncated[i + 1] == ' ') {
          lastSentenceEnd = i;
          break;
        }
      }
    }
    
    if (lastSentenceEnd > 0) {
      // Truncate at sentence boundary
      return truncated.substring(0, lastSentenceEnd + 1).trim();
    } else {
      // Fallback: truncate at word boundary
      final words = truncated.split(' ');
      words.removeLast(); // Remove potentially incomplete word
      return '${words.join(' ')}...';
    }
  }

  /// Test the character limit functionality (for debugging)
  String testCharacterLimit() {
    const longResponse = '''This is a very long response that would exceed our character limit. It has multiple sentences to test the smart truncation. The system should cut off at a sentence boundary. This sentence should be included. But this one might be cut off depending on where we are in the character count. This is definitely too long and should be truncated. We want to make sure it ends gracefully.''';
    
    final result = _applyResponseLimit(longResponse, maxCharacters: 200);
    print('Original: ${longResponse.length} chars');
    print('Truncated: ${result.length} chars');
    print('Result: $result');
    return result;
  }
  
  /// Extract user content only (filter out template/AI content)
  String _extractUserContentOnly(String content) {
    if (content.trim().isEmpty) return '';
    
    // Light filtering for journal content - only remove truly empty content
    String cleanContent = content;
    
    // Remove excessive whitespace but preserve structure
    cleanContent = cleanContent.replaceAll(RegExp(r'\n\s*\n\s*\n+'), '\n\n');
    cleanContent = cleanContent.trim();
    
    return cleanContent;
  }



  /// Truncate text to fit within token budget, stopping at sentence boundaries
  String _truncateToTokenBudget(String text, int tokenBudget) {
    if (_estimateTokens(text) <= tokenBudget) {
      return text;
    }

    final sentences = text.split(RegExp(r'[.!?]+\s+'));
    final result = <String>[];
    int currentTokens = 0;

    for (final sentence in sentences) {
      final sentenceTokens = _estimateTokens(sentence + '. ');
      if (currentTokens + sentenceTokens <= tokenBudget) {
        result.add(sentence);
        currentTokens += sentenceTokens;
      } else {
        break;
      }
    }

    return result.isNotEmpty ? result.join('. ') + '.' : '';
  }

  /// Estimate tokens in text (rough approximation)
  int _estimateTokens(String text) {
    if (text.trim().isEmpty) return 0;
    
    // More accurate token estimation:
    // - Count words and punctuation separately
    // - Average English word is ~1.3 tokens
    // - Punctuation and spaces add overhead
    final words = text.trim().split(RegExp(r'\s+'));
    final wordTokens = (words.length * 1.3).ceil();
    
    // Add overhead for formatting, punctuation, etc.
    final overhead = (text.length * 0.1).ceil();
    
    return wordTokens + overhead;
  }

  /// DEBUGGING: Test the embedding system with a simple query
  Future<void> debugEmbeddingSystem({String testQuery = "work"}) async {
    print('üß™ DEBUGGING EMBEDDING SYSTEM WITH QUERY: "$testQuery"');
    
    try {
      // 1. Check database state
      final embeddingCount = await _dbService.getEmbeddingCount();
      print('   üìä Database embeddings: $embeddingCount');
      
      if (embeddingCount == 0) {
        print('   ‚ùå No embeddings found - import files first!');
        return;
      }
      
      // 2. Test query embedding generation
      final queryEmbedding = await _embeddingService.generateEmbedding(testQuery);
      print('   üß† Query embedding: length=${queryEmbedding.length}, sum=${queryEmbedding.fold(0.0, (a, b) => a + b).toStringAsFixed(4)}');
      
      // 3. Test direct database parsing (NEW)
      final db = await _dbService.database;
      final sampleRows = await db.rawQuery('SELECT embedding FROM file_embeddings LIMIT 1');
      if (sampleRows.isNotEmpty) {
        final rawEmbedding = sampleRows.first['embedding'];
        final parsedEmbedding = _embeddingService.parseChunkedEmbedding(rawEmbedding);
        print('   üîß PARSING TEST: Raw embedding type=${rawEmbedding.runtimeType}, parsed length=${parsedEmbedding.length}');
      }
      
      // 4. Test similarity search
      final similarFiles = await _embeddingService.findSimilarFiles(testQuery, topK: 5);
      print('   üéØ Similar files found: ${similarFiles.length}');
      
      // 5. Test content processing
      int validContentCount = 0;
      for (final file in similarFiles) {
        final cleanContent = _extractUserContentOnly(file.content);
        if (cleanContent.isNotEmpty) {
          validContentCount++;
          print('   ‚úÖ File "${file.name}": ${cleanContent.length} chars after filtering');
        } else {
          print('   ‚ùå File "${file.name}": Empty after filtering (original: ${file.content.length} chars)');
        }
      }
      
      print('   üìä Files with valid content: $validContentCount/${similarFiles.length}');
      
      // 6. Test token estimation
      final tokenBudget = 5000;
      print('   üí∞ Testing with token budget: $tokenBudget');
      
      if (validContentCount == 0) {
        print('   ‚ùå ISSUE: No files have valid content after filtering!');
      } else {
        print('   ‚úÖ Embedding system appears functional');
      }
      
    } catch (e) {
      print('   ‚ùå ERROR during embedding debug: $e');
      print('   üìç Stack trace: ${StackTrace.current}');
    }
  }

  /// CLEANUP: Clear corrupted embeddings and regenerate them
  Future<void> fixCorruptedEmbeddings() async {
    print('üîß FIXING CORRUPTED EMBEDDINGS...');
    
    try {
      // 1. Clear all existing embeddings
      final db = await _dbService.database;
      await db.delete('file_embeddings');
      print('   üóëÔ∏è Cleared all existing embeddings');
      
      // 2. Get all files that need embeddings
      final allFiles = await _dbService.getFiles();
      print('   üìÑ Found ${allFiles.length} files to re-embed');
      
      // 3. Regenerate embeddings for each file
      int processed = 0;
      for (final fileMetadata in allFiles) {
        try {
          processed++;
          print('   üìÑ Processing ${processed}/${allFiles.length}: ${fileMetadata.name}');
          
          // Load full file content
          final file = await _dbService.getFile(fileMetadata.id);
          if (file?.content?.isNotEmpty == true) {
            // Generate embeddings using the import service chunking logic
            final chunks = _chunkContent(file!.content!);
            print('     üß† Generating ${chunks.length} chunks...');
            
            for (int i = 0; i < chunks.length; i++) {
              final embedding = await _embeddingService.generateEmbedding(chunks[i]);
              await _dbService.storeChunkedEmbedding(file.id, i, chunks[i], embedding);
            }
            
            print('     ‚úÖ Generated ${chunks.length} embeddings');
          } else {
            print('     ‚è≠Ô∏è Skipped (no content)');
          }
        } catch (e) {
          print('     ‚ùå Error processing ${fileMetadata.name}: $e');
        }
      }
      
      final finalCount = await _dbService.getEmbeddingCount();
      print('   üéâ COMPLETE: Generated $finalCount fresh embeddings');
      
    } catch (e) {
      print('   ‚ùå ERROR during embedding regeneration: $e');
    }
  }

  /// Helper: Chunk content similar to import service
  List<String> _chunkContent(String content) {
    final paragraphs = content.split('\n\n');
    final chunks = <String>[];
    String currentChunk = '';
    
    for (final paragraph in paragraphs) {
      final testChunk = currentChunk.isEmpty ? paragraph : '$currentChunk\n\n$paragraph';
      final wordCount = testChunk.split(' ').length;
      
      if (wordCount > 500 && currentChunk.isNotEmpty) {
        chunks.add(currentChunk.trim());
        currentChunk = paragraph;
      } else {
        currentChunk = testChunk;
      }
    }
    
    if (currentChunk.isNotEmpty) {
      chunks.add(currentChunk.trim());
    }
    
    return chunks.isEmpty ? [content] : chunks;
  }
}